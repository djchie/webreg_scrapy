# Commands to run:

  - scrapy crawl department_scrapy -o departments.json
    - To crawl departments and store them into departments.json
  - scrapy crawl course_scrapy -o courses.json
    - To crawl courses and store them into courses.json

# TODO:
  
## Process:

  - Execute the department spider to grab updated list of departments
  - Execute a course spider for each department in department list
  - Upload all the information to Parse
    - https://realpython.com/blog/python/web-scraping-with-scrapy-and-mongodb/

